{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfDwaWNTZCZ"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This notebook uses perch-hoplite to compute and save embeddings for set of audio files using a pre-trained model. This is the first step in the agile modeling process. If the data you wish to search and classify is already embedded with a pre-trained model into a perch-hoplite database, then proceed to the step 2 colab notebook ([2_agile_modeling_v2.ipynb](https://github.com/google-research/perch-hoplite/blob/main/perch_hoplite/agile/2_agile_modeling_v2.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Db84ySxSJYA"
      },
      "source": [
        "## [Optional] perch-hoplite installation for hosted runtimes\n",
        "\n",
        "If you have not already installed perch-hoplite (particularly if you are using a hosted Colab runtime), make sure to install perch-hoplite from the Github source to ensure the most recent version is installed. After installation, you will need to restart your runtime before running anything else. Go to the top menu, select \"Runtime\" then \"Restart Session\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7bUZkS_Rawd"
      },
      "outputs": [],
      "source": [
        "#@title Only run this code if you need to install perch-hoplite\n",
        "!pip install git+https://github.com/google-research/perch-hoplite.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTtVnkC-6_i7"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "from etils import epath\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "from perch_hoplite.agile import colab_utils\n",
        "from perch_hoplite.agile import embed\n",
        "from perch_hoplite.agile import source_info\n",
        "from perch_hoplite.db import brutalism\n",
        "from perch_hoplite.db import interface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Google Drive"
      ],
      "metadata": {
        "id": "fk4TQ1wVgA1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GzzeL6I2gFgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Target Folder"
      ],
      "metadata": {
        "id": "3a8H7WQngLR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create a new folder in Drive (if it doesn't already exist) within your Google drive.\n",
        "base_dir = '/content/drive/MyDrive/'\n",
        "#@ markdown Name of your new folder in Drive\n",
        "new_folder_name = 'whale_denoising' #@param\n",
        "\n",
        "drive_output_directory = base_dir + new_folder_name\n",
        "\n",
        "try:\n",
        "  if not os.path.exists(drive_output_directory):\n",
        "    os.makedirs(drive_output_directory, exist_ok=True)\n",
        "    print(f'Directory {drive_output_directory} created successfully.')\n",
        "  else:\n",
        "    print(f'Directory {drive_output_directory} already exists.')\n",
        "except OSError as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "1ZX6BJz6gOLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T4vILrO80iP"
      },
      "source": [
        "# Embed the audio data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6zdGxl68vft"
      },
      "outputs": [],
      "source": [
        "# @title Configuration { vertical-output: true }\n",
        "\n",
        "# @markdown Configure the raw dataset and output location(s).  The format is a mapping from\n",
        "# @markdown a dataset_name to a (base_path, fileglob) pair.  Note that the file\n",
        "# @markdown globs are case sensitive.  The dataset name can be anything you want.\n",
        "#\n",
        "# @markdown This structure allows you to move your data around without having to\n",
        "# @markdown re-embed the dataset.  The generated embedding database will be\n",
        "# @markdown placed in the base path. This allows you to simply swap out\n",
        "# @markdown the base path here if you ever move your dataset.\n",
        "\n",
        "# @markdown By default we only process one dataset at a time.  Re-run this entire notebook\n",
        "# @markdown once per dataset.\n",
        "\n",
        "# @markdown For example, we might set dataset_base_path to '/home/me/myproject',\n",
        "# @markdown and use the glob '\\*/\\*.wav' if all of the audio files have filepaths\n",
        "# @markdown like '/home/me/myproject/site_XYZ/audio_ABC.wav' (e.g. audio files are contained in subfolders of the base directory).\n",
        "\n",
        "# @markdown 1. Create a unique name for the database that will store the embeddings for the target data.\n",
        "dataset_name = 'WhaleDenoising'  # @param {type:'string'}\n",
        "# @markdown 2. Input the filepath for the folder that is containing the input audio files.\n",
        "# dataset_base_path = ''  #@param {type:'string'}\n",
        "# dataset_base_path = '/content/drive/MyDrive/whale_denoising'\n",
        "dataset_base_path = drive_output_directory\n",
        "# @markdown 3. Input the file pattern for the audio files within that folder that you want to embed. Some examples for how to input:\n",
        "# @markdown - All files in the base directory of a specific type (not subdirectories): e.g. `*.wav` (or `*.flac` etc) will generate embeddings for all .wav files (or whichever format) in the dataset_base_path\n",
        "# @markdown - All files in one level of subdirectories within the base directory: `*/*.flac` will generate embeddings for all .flac files\n",
        "# @markdown - Single file: `myfile.wav` will only embed the audio from that specific file.\n",
        "dataset_fileglob = '*/*.wav'  # @param {type:'string'}\n",
        "\n",
        "# @markdown 4. [Optional] If saving the embeddings database to a new directory, specify here.\n",
        "# @markdown Otherwise, leave blank - by default the embeddings database output will be saved within\n",
        "# @markdown dataset_base_path where the audio is located. You do not need to specify db_path unless you want to maintain multiple\n",
        "# @markdown distinct embedding databases, or if you would like to save the output\n",
        "# @markdown in a different folder. If your input audio data is accessed\n",
        "# @markdown from a public URL, we recommend specifying a separate output directory here.\n",
        "# db_path = '/content/drive/MyDrive/whale_denoising'  # @param {type:'string'}\n",
        "db_path = drive_output_directory\n",
        "if not db_path or db_path == 'None':\n",
        "  db_path = None\n",
        "\n",
        "# @markdown 5. Choose a supported model to generate embeddings: `perch_8` or `birdnet_v2.3` are most common\n",
        "# @markdown for birds. Other choices include `surfperch` for coral reefs or\n",
        "# @markdown `multispecies_whale` for marine mammals.\n",
        "model_choice = 'humpback'  #@param['humpback', 'multispecies_whale', 'perch_8', 'surfperch', 'birdnet_V2.3']\n",
        "\n",
        "# @markdown 6. [Optional] Shard the audio for embeddings. File sharding automatically splits audio files into smaller chunks\n",
        "# @markdown for creating embeddings. This limits both system and GPU memory usage,\n",
        "# @markdown especially useful when working with long files (>1 hour).\n",
        "use_file_sharding = True  # @param {type:'boolean'}\n",
        "# @markdown If you want to change the length in seconds for the shards, specify here.\n",
        "shard_length_in_seconds = 60  # @param {type:'number'}\n",
        "\n",
        "audio_glob = source_info.AudioSourceConfig(\n",
        "    dataset_name=dataset_name,\n",
        "    base_path=dataset_base_path,\n",
        "    file_glob=dataset_fileglob,\n",
        "    min_audio_len_s=1.0,\n",
        "    target_sample_rate_hz=-2,\n",
        "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\n",
        ")\n",
        "\n",
        "configs = colab_utils.load_configs(\n",
        "    source_info.AudioSources((audio_glob,)),\n",
        "    db_path,\n",
        "    model_config_key=model_choice,\n",
        "    db_key='sqlite_usearch',\n",
        ")\n",
        "configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN9Uyy1yqAWS"
      },
      "outputs": [],
      "source": [
        "#@title Initialize the hoplite database (DB) { vertical-output: true }\n",
        "global db\n",
        "db = configs.db_config.load_db()\n",
        "num_embeddings = db.count_embeddings()\n",
        "\n",
        "print('Initialized DB located at ', configs.db_config.db_config.db_path)\n",
        "\n",
        "def drop_and_reload_db(_) -> interface.HopliteDBInterface:\n",
        "  db_path = epath.Path(configs.db_config.db_config.db_path)\n",
        "  for fp in db_path.glob('hoplite.sqlite*'):\n",
        "    fp.unlink()\n",
        "  (db_path / 'usearch.index').unlink()\n",
        "  print('\\n Deleted previous db at: ', configs.db_config.db_config.db_path)\n",
        "  db = configs.db_config.load_db()\n",
        "\n",
        "#@markdown If `drop_existing_db` set to True, when the database already exists and contains embeddings,\n",
        "#@markdown then those existing embeddings will be erased. You will be prompted to confirm you wish to delete those existing\n",
        "#@markdown embeddings. If you want to keep existing embeddings in the database, then set to False, which will append the new\n",
        "#@markdown embeddings to the database.\n",
        "drop_existing_db = False  #@param {type:'boolean'}\n",
        "\n",
        "if num_embeddings > 0 and drop_existing_db:\n",
        "  print('Existing DB contains datasets: ', db.get_dataset_names())\n",
        "  print('num embeddings: ', num_embeddings)\n",
        "  print('\\n\\nClick the button below to confirm you really want to drop the database at ')\n",
        "  print(f'{configs.db_config.db_config.db_path}\\n')\n",
        "  print(f'This will permanently delete all {num_embeddings} embeddings from the existing database.\\n')\n",
        "  print('If you do NOT want to delete this data, set `drop_existing_db` above to `False` and re-run this cell.\\n')\n",
        "\n",
        "  button = widgets.Button(description='Delete database?')\n",
        "  button.on_click(drop_and_reload_db)\n",
        "  display(button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnGWbhc0LhiU"
      },
      "outputs": [],
      "source": [
        "#@title Run the embedding { vertical-output: true }\n",
        "\n",
        "print(f'Embedding dataset: {audio_glob.dataset_name}')\n",
        "\n",
        "worker = embed.EmbedWorker(\n",
        "    audio_sources=configs.audio_sources_config,\n",
        "    db=db,\n",
        "    model_config=configs.model_config)\n",
        "\n",
        "worker.process_all(target_dataset_name=audio_glob.dataset_name)\n",
        "\n",
        "print('\\n\\nEmbedding complete, total embeddings: ', db.count_embeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvVuFw-somHe"
      },
      "outputs": [],
      "source": [
        "#@title Per dataset statistics { vertical-output: true }\n",
        "\n",
        "for dataset in db.get_dataset_names():\n",
        "  print(f'\\nDataset \\'{dataset}\\':')\n",
        "  print('\\tnum embeddings: ', db.get_embeddings_by_source(dataset, source_id=None).shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ihBNRbwuuwal"
      },
      "outputs": [],
      "source": [
        "#@title Show example embedding search\n",
        "#@markdown As an example (and to show that the embedding process worked), this\n",
        "#@markdown selects a single embedding from the database and outputs the embedding ids of the\n",
        "#@markdown top-K (k = 128) nearest neighbors in the database.\n",
        "\n",
        "q = db.get_embedding(db.get_one_embedding_id())\n",
        "%time results, scores = brutalism.brute_search(worker.db, query_embedding=q, search_list_size=128, score_fn=np.dot)\n",
        "print([int(r.embedding_id) for r in results])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(db)"
      ],
      "metadata": {
        "id": "z8M5JOE_mifF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65e3c3ca"
      },
      "source": [
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Construct the full path to the SQLite database file\n",
        "db_file_path = os.path.join(configs.db_config.db_config.db_path, 'hoplite.sqlite')\n",
        "\n",
        "# Connect to the SQLite database\n",
        "try:\n",
        "    conn = sqlite3.connect(db_file_path)\n",
        "    cursor = conn.cursor()\n",
        "    print(f\"Connected to the database at: {db_file_path}\")\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error connecting to the database: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "594b94f6"
      },
      "source": [
        "Now that you're connected to the database, you can execute SQL queries in the cells below.\n",
        "\n",
        "Here are some example queries to get you started:\n",
        "\n",
        "*   **List all tables:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49094a76"
      },
      "source": [
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "print(\"Tables in the database:\")\n",
        "for table in tables:\n",
        "    print(table[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7c1821e"
      },
      "source": [
        "# Replace 'your_table_name' with an actual table name from the output above\n",
        "table_name = 'hoplite_labels'\n",
        "try:\n",
        "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "    columns = cursor.fetchall()\n",
        "    print(f\"\\nColumns in the '{table_name}' table:\")\n",
        "    for col in columns:\n",
        "        print(col[1])\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error querying table info: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    cursor.execute(\"SELECT * FROM hoplite_labels;\")\n",
        "    rows = cursor.fetchall()\n",
        "    print(\"Contents of the 'hoplite_labels' table:\")\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error querying hoplite_labels table: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "p6cJ9K0cnwKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    cursor.execute(\"SELECT * FROM hoplite_sources;\")\n",
        "    rows = cursor.fetchall()\n",
        "    print(\"Contents of the 'hoplite_sources' table:\")\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error querying hoplite_sources table: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x5uSkcBtnOvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Delete existing labels\n",
        "    cursor.execute(\"DELETE FROM hoplite_labels;\")\n",
        "    conn.commit()\n",
        "    print(\"Successfully deleted existing labels from hoplite_labels table.\")\n",
        "\n",
        "    # Insert new labels based on source folder\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT INTO hoplite_labels (embedding_id, label, type, provenance)\n",
        "        SELECT\n",
        "            he.id,\n",
        "            CASE\n",
        "                -- Check if the source path contains 'clean/'\n",
        "                WHEN INSTR(hs.source, 'clean/') > 0 THEN 'clean'\n",
        "                -- Check if the source path contains 'noisy/'\n",
        "                WHEN INSTR(hs.source, 'noisy/') > 0 THEN 'noisy'\n",
        "                ELSE 'unknown'\n",
        "            END AS label,\n",
        "            'user_provided' AS type,\n",
        "            'labeled based on source folder' AS provenance\n",
        "        FROM hoplite_embeddings he\n",
        "        JOIN hoplite_sources hs ON he.source_idx = hs.id;\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "    print(\"Successfully populated hoplite_labels table.\")\n",
        "\n",
        "    # Check the counts of each label\n",
        "    cursor.execute(\"SELECT label, COUNT(*) FROM hoplite_labels GROUP BY label;\")\n",
        "    label_counts = cursor.fetchall()\n",
        "    print(\"\\nCounts of labels in the hoplite_labels table:\")\n",
        "    for label, count in label_counts:\n",
        "        print(f\"Label: {label}, Count: {count}\")\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error populating hoplite_labels table: {e}\")"
      ],
      "metadata": {
        "id": "f0qIzmg5n9vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "42d3f858"
      },
      "source": [
        "try:\n",
        "    cursor.execute(\"SELECT * FROM hoplite_labels;\")\n",
        "    rows = cursor.fetchall()\n",
        "    print(\"Contents of the 'hoplite_labels' table:\")\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Error querying hoplite_labels table: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "whale_denoising.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}